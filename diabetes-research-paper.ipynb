{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":482,"sourceType":"datasetVersion","datasetId":228}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ndiabetes = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\ndf = pd.DataFrame(diabetes)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-11T14:54:17.905234Z","iopub.execute_input":"2023-12-11T14:54:17.905664Z","iopub.status.idle":"2023-12-11T14:54:17.928214Z","shell.execute_reply.started":"2023-12-11T14:54:17.905632Z","shell.execute_reply":"2023-12-11T14:54:17.926703Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X = df.drop('Outcome', axis=1)\ny = df['Outcome']","metadata":{"execution":{"iopub.status.busy":"2023-12-11T14:56:38.324190Z","iopub.execute_input":"2023-12-11T14:56:38.324622Z","iopub.status.idle":"2023-12-11T14:56:38.332372Z","shell.execute_reply.started":"2023-12-11T14:56:38.324569Z","shell.execute_reply":"2023-12-11T14:56:38.330941Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2023-12-11T15:00:25.613908Z","iopub.execute_input":"2023-12-11T15:00:25.614314Z","iopub.status.idle":"2023-12-11T15:00:25.636738Z","shell.execute_reply.started":"2023-12-11T15:00:25.614283Z","shell.execute_reply":"2023-12-11T15:00:25.635466Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0              6      148             72             35        0  33.6   \n1              1       85             66             29        0  26.6   \n2              8      183             64              0        0  23.3   \n3              1       89             66             23       94  28.1   \n4              0      137             40             35      168  43.1   \n..           ...      ...            ...            ...      ...   ...   \n763           10      101             76             48      180  32.9   \n764            2      122             70             27        0  36.8   \n765            5      121             72             23      112  26.2   \n766            1      126             60              0        0  30.1   \n767            1       93             70             31        0  30.4   \n\n     DiabetesPedigreeFunction  Age  \n0                       0.627   50  \n1                       0.351   31  \n2                       0.672   32  \n3                       0.167   21  \n4                       2.288   33  \n..                        ...  ...  \n763                     0.171   63  \n764                     0.340   27  \n765                     0.245   30  \n766                     0.349   47  \n767                     0.315   23  \n\n[768 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>10</td>\n      <td>101</td>\n      <td>76</td>\n      <td>48</td>\n      <td>180</td>\n      <td>32.9</td>\n      <td>0.171</td>\n      <td>63</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>2</td>\n      <td>122</td>\n      <td>70</td>\n      <td>27</td>\n      <td>0</td>\n      <td>36.8</td>\n      <td>0.340</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>5</td>\n      <td>121</td>\n      <td>72</td>\n      <td>23</td>\n      <td>112</td>\n      <td>26.2</td>\n      <td>0.245</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>1</td>\n      <td>126</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.1</td>\n      <td>0.349</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>1</td>\n      <td>93</td>\n      <td>70</td>\n      <td>31</td>\n      <td>0</td>\n      <td>30.4</td>\n      <td>0.315</td>\n      <td>23</td>\n    </tr>\n  </tbody>\n</table>\n<p>768 rows Ã— 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n\n# Perform train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Build the MLP model\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)),\n    tf.keras.layers.Dense(units=64, activation='relu'),\n    tf.keras.layers.Dense(units=1, activation='sigmoid')\n])\n\n# Compile the model\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n\n\n\n\n# Train the model\nmodel.fit(X_train, y_train,epochs=10, batch_size=32)\n\n# Evaluate the model\nloss, accuracy = model.evaluate(X_test, y_test)\n\nprint(loss, accuracy )","metadata":{"execution":{"iopub.status.busy":"2023-12-11T15:08:23.946881Z","iopub.execute_input":"2023-12-11T15:08:23.947423Z","iopub.status.idle":"2023-12-11T15:08:25.575956Z","shell.execute_reply.started":"2023-12-11T15:08:23.947380Z","shell.execute_reply":"2023-12-11T15:08:25.573801Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/10\n20/20 [==============================] - 1s 2ms/step - loss: 0.6381 - accuracy: 0.6466\nEpoch 2/10\n20/20 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7524\nEpoch 3/10\n20/20 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7769\nEpoch 4/10\n20/20 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7915\nEpoch 5/10\n20/20 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7997\nEpoch 6/10\n20/20 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7980\nEpoch 7/10\n20/20 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7997\nEpoch 8/10\n20/20 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7964\nEpoch 9/10\n20/20 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8029\nEpoch 10/10\n20/20 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7997\n5/5 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7662\n0.5126533508300781 0.7662337422370911\n","output_type":"stream"}]}]}